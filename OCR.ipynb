{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBnLRl0I6QTCRkhp4yO6XU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniket21628/OCR/blob/main/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP-jSf84RecZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01268bf2-24cc-4aca-f69b-8253f9b9a25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy pandas scikit-learn tensorflow keras imutils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sachinpatel21/az-handwritten-alphabets-in-csv-format\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts4TxBl7UQoy",
        "outputId": "5e79e154-a54e-402f-c60e-d6330475670c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/az-handwritten-alphabets-in-csv-format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "AwGS3x5AZ5qE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_kaggle_dataset():\n",
        "    \"\"\"Process Kaggle A-Z handwritten dataset (CSV format) - UPDATED\"\"\"\n",
        "    df = pd.read_csv(\"/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\")\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    # Use iloc for positional access\n",
        "    for i in range(len(df)):\n",
        "        row = df.iloc[i]\n",
        "        label = int(row.iloc[0])  # First column is label\n",
        "        pixels = row.iloc[1:].values.astype(\"uint8\")  # Remaining columns are pixels\n",
        "\n",
        "        # Reshape to 28x28\n",
        "        pixels = pixels.reshape((28, 28))\n",
        "        data.append(pixels)\n",
        "        labels.append(label + 10)  # Offset: A=10, B=11, ..., Z=35\n",
        "\n",
        "    return np.array(data, dtype=\"float32\"), np.array(labels, dtype=\"int\")"
      ],
      "metadata": {
        "id": "Wnb8D3pQaYjD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mnist():\n",
        "    \"\"\"Process MNIST dataset\"\"\"\n",
        "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "    mnist_data = np.vstack([train_data, test_data])\n",
        "    mnist_labels = np.hstack([train_labels, test_labels])\n",
        "    return mnist_data.astype(\"float32\"), mnist_labels"
      ],
      "metadata": {
        "id": "WW5g2ZWparQL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/surrey"
      ],
      "metadata": {
        "id": "eTUaLqcWbpTv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz -O data/english.tgz\n",
        "!tar -xf data/english.tgz -C data/surrey/"
      ],
      "metadata": {
        "id": "_VG2VKF-bta4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf data/english.tgz -C data/surrey/ --strip-components=1"
      ],
      "metadata": {
        "id": "nh9lfo-5b6TG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if files exist\n",
        "surrey_path = \"data/surrey/English/Img/GoodImg/Bmp\"\n",
        "if os.path.exists(surrey_path):\n",
        "    print(f\"Found {len(os.listdir(surrey_path))} character folders\")\n",
        "    sample_folder = os.path.join(surrey_path, os.listdir(surrey_path)[0])\n",
        "    print(f\"Sample folder contains {len(os.listdir(sample_folder))} images\")\n",
        "else:\n",
        "    print(\"Dataset not found. Manual download required.\")\n",
        "    print(\"Please download from: https://github.com/sachinpatel21/Chars74k_Dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1dar5bMcT-R",
        "outputId": "0c437d72-fba9-42dd-87f6-4a7b5e8c1c62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 62 character folders\n",
            "Sample folder contains 64 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_surrey_dataset():\n",
        "    \"\"\"Process University of Surrey dataset (image files)\"\"\"\n",
        "    SURREY_PATH = \"data/surrey/English/Img/GoodImg/Bmp\"\n",
        "    characters = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    # Sort folders numerically (Sample001, Sample002, etc)\n",
        "    folders = sorted(\n",
        "        [f for f in os.listdir(SURREY_PATH) if f.startswith(\"Sample\")],\n",
        "        key=lambda x: int(x[6:])\n",
        "    )\n",
        "\n",
        "    for idx, folder in enumerate(folders):\n",
        "        char_path = os.path.join(SURREY_PATH, folder)\n",
        "        if not os.path.isdir(char_path):\n",
        "            continue\n",
        "\n",
        "        for img_file in os.listdir(char_path):\n",
        "            if img_file.startswith(\".\"):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(char_path, img_file)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            resized = cv2.resize(gray, (28, 28))\n",
        "            data.append(resized)\n",
        "            labels.append(idx)  # Use folder index as label\n",
        "\n",
        "    return np.array(data, dtype=\"float32\"), np.array(labels, dtype=\"int\")"
      ],
      "metadata": {
        "id": "xDX-3RF_cepY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing MNIST dataset...\")\n",
        "mnist_data, mnist_labels = process_mnist()\n",
        "\n",
        "print(\"Processing Kaggle A-Z dataset...\")\n",
        "kaggle_data, kaggle_labels = process_kaggle_dataset()\n",
        "\n",
        "print(\"Processing Surrey dataset...\")\n",
        "surrey_data, surrey_labels = process_surrey_dataset()\n",
        "\n",
        "# Verify datasets\n",
        "print(f\"MNIST: {mnist_data.shape[0]} images\")\n",
        "print(f\"Kaggle: {kaggle_data.shape[0]} images\")\n",
        "print(f\"Surrey: {surrey_data.shape[0]} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7eeYbw_cc8li",
        "outputId": "cf82f0a1-9999-4d25-ba5b-dc781b762f9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing MNIST dataset...\n",
            "Processing Kaggle A-Z dataset...\n",
            "Processing Surrey dataset...\n",
            "MNIST: 70000 images\n",
            "Kaggle: 372450 images\n",
            "Surrey: 7705 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = np.vstack([mnist_data, kaggle_data, surrey_data])\n",
        "combined_labels = np.hstack([mnist_labels, kaggle_labels, surrey_labels])"
      ],
      "metadata": {
        "id": "CoPeD_LqfUG9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"combined_data.npy\", combined_data)\n",
        "np.save(\"combined_labels.npy\", combined_labels)\n",
        "print(f\"Combined dataset size: {combined_data.shape[0]} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6G4Ug3GfX9t",
        "outputId": "debbe527-cf05-4c18-afbb-0367586ecabd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset size: 450155 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load combined dataset\n",
        "data = np.load(\"combined_data.npy\")\n",
        "labels = np.load(\"combined_labels.npy\")"
      ],
      "metadata": {
        "id": "6PiiGTMRfd-0"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}